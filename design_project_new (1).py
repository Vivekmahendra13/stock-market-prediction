# -*- coding: utf-8 -*-
"""Design Project New.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Sr0ITOQNMz0x0dPuGPtl9TxnWCYrngpT
"""

!pip install mplfinance pandas

import pandas as pd
import matplotlib.pyplot as plt
import os

# Define paths
csv_file_path = 'ADANIPORTS.csv'  # Update this path to your actual CSV file path
output_folder = 'candlestick_images'  # Folder to save candlestick images

# Create the output folder if it doesn't exist
os.makedirs(output_folder, exist_ok=True)

# Load the CSV data
try:
    stock_data = pd.read_csv(csv_file_path)

    # Ensure required columns exist
    required_columns = {'Date', 'Open', 'High', 'Low', 'Close'}
    if not required_columns.issubset(stock_data.columns):
        raise ValueError(f"The CSV file must contain these columns: {', '.join(required_columns)}")

    # Convert 'Date' column to datetime
    stock_data['Date'] = pd.to_datetime(stock_data['Date'])
    stock_data = stock_data.sort_values('Date')  # Sort data by date

    # Generate candlestick images for each day in stock data
    for _, row in stock_data.iterrows():
        date, open_price, high_price, low_price, close_price = row['Date'], row['Open'], row['High'], row['Low'], row['Close']

        # Initialize a figure and axis
        fig, ax = plt.subplots(figsize=(2, 4))  # Aspect ratio for candlestick chart
        color = 'green' if close_price >= open_price else 'red'  # Green for bullish, red for bearish

        # Plot candlestick body
        ax.bar(date, abs(close_price - open_price), bottom=min(open_price, close_price), color=color, width=0.4)

        # Plot high and low wicks
        ax.vlines(date, low_price, high_price, color='black', linewidth=0.6)

        # Adjust plot aesthetics
        ax.set_xlim(date - pd.Timedelta(days=0.5), date + pd.Timedelta(days=0.5))
        ax.set_ylim(low_price - (0.05 * low_price), high_price + (0.05 * high_price))
        ax.axis('off')  # Hide axes

        # Save the figure
        image_path = os.path.join(output_folder, f"{date.strftime('%Y-%m-%d')}.png")
        plt.savefig(image_path, bbox_inches='tight', pad_inches=0.1)
        plt.close(fig)  # Close the figure to free memory

    print(f"Candlestick images successfully saved in the '{output_folder}' folder.")

except FileNotFoundError:
    print(f"Error: The file '{csv_file_path}' was not found. Please check the file path.")
except Exception as e:
    print(f"An error occurred: {e}")

import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing.image import load_img
import os

# Parameters
image_folder_path = 'candlestick_images'  # Folder where images are extracted
num_images_to_display = 10  # Number of images to display

# Get list of image files in the folder
image_files = sorted([f for f in os.listdir(image_folder_path) if f.endswith('.png')])

# Display a few candlestick images
plt.figure(figsize=(10, 10))
for i, image_file in enumerate(image_files[:num_images_to_display]):
    img_path = os.path.join(image_folder_path, image_file)
    img = load_img(img_path, color_mode='grayscale')

    plt.subplot(2, 5, i + 1)  # Display in a 2x5 grid for 10 images
    plt.imshow(img, cmap='gray')
    plt.axis('off')
    plt.title(image_file)

plt.tight_layout()
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
import os

# Define paths
csv_file_path = 'ADANIPORTS.csv'  # Update this path to your actual CSV file path
output_folder = 'candlestick_images'  # Folder to save candlestick images

# Create the output folder if it doesn't exist
os.makedirs(output_folder, exist_ok=True)

# Load the CSV data
try:
    stock_data = pd.read_csv(csv_file_path)

    # Ensure required columns exist
    required_columns = {'Date', 'Open', 'High', 'Low', 'Close'}
    if not required_columns.issubset(stock_data.columns):
        raise ValueError(f"The CSV file must contain these columns: {', '.join(required_columns)}")

    # Convert 'Date' column to datetime
    stock_data['Date'] = pd.to_datetime(stock_data['Date'])
    stock_data = stock_data.sort_values('Date')  # Sort data by date

    # Generate candlestick images for each day in stock data
    for _, row in stock_data.iterrows():
        date, open_price, high_price, low_price, close_price = row['Date'], row['Open'], row['High'], row['Low'], row['Close']

        # Determine if the movement is up or down
        movement = "Up" if close_price >= open_price else "Down"
        color = 'green' if movement == "Up" else 'red'

        # Initialize a figure and axis
        fig, ax = plt.subplots(figsize=(2, 4))  # Aspect ratio for candlestick chart

        # Plot candlestick body
        ax.bar(date, abs(close_price - open_price), bottom=min(open_price, close_price), color=color, width=0.4)

        # Plot high and low wicks
        ax.vlines(date, low_price, high_price, color='black', linewidth=0.6)

        # Add labels for open and close prices
        ax.text(date, open_price, f'Open: {open_price}', ha='center', va='bottom', color='blue', fontsize=8)
        ax.text(date, close_price, f'Close: {close_price}', ha='center', va='top', color='purple', fontsize=8)

        # Add movement label
        ax.text(date, high_price + (0.05 * high_price), movement, ha='center', color=color, fontsize=10, weight='bold')

        # Adjust plot aesthetics
        ax.set_xlim(date - pd.Timedelta(days=0.5), date + pd.Timedelta(days=0.5))
        ax.set_ylim(low_price - (0.1 * low_price), high_price + (0.1 * high_price))
        ax.axis('off')  # Hide axes

        # Save the figure
        image_path = os.path.join(output_folder, f"{date.strftime('%Y-%m-%d')}.png")
        plt.savefig(image_path, bbox_inches='tight', pad_inches=0.1)
        plt.close(fig)  # Close the figure to free memory

    print(f"Candlestick images successfully saved in the '{output_folder}' folder.")

except FileNotFoundError:
    print(f"Error: The file '{csv_file_path}' was not found. Please check the file path.")
except Exception as e:
    print(f"An error occurred: {e}")

import pandas as pd
import matplotlib.pyplot as plt
import os

# Define paths
csv_file_path = 'ADANIPORTS.csv'  # Update this path to your actual CSV file path
output_folder = 'candlestick_images'  # Folder to save candlestick images

# Create the output folder if it doesn't exist
os.makedirs(output_folder, exist_ok=True)

# Load the CSV data
try:
    stock_data = pd.read_csv(csv_file_path)

    # Ensure required columns exist
    required_columns = {'Date', 'Open', 'High', 'Low', 'Close'}
    if not required_columns.issubset(stock_data.columns):
        raise ValueError(f"The CSV file must contain these columns: {', '.join(required_columns)}")

    # Convert 'Date' column to datetime
    stock_data['Date'] = pd.to_datetime(stock_data['Date'])
    stock_data = stock_data.sort_values('Date')  # Sort data by date

    # Generate candlestick images for each day in stock data
    for _, row in stock_data.iterrows():
        date, open_price, high_price, low_price, close_price = row['Date'], row['Open'], row['High'], row['Low'], row['Close']

        # Initialize a figure and axis
        fig, ax = plt.subplots(figsize=(2, 4))  # Aspect ratio for candlestick chart
        color = 'green' if close_price >= open_price else 'red'  # Green for bullish, red for bearish

        # Plot candlestick body
        ax.bar(date, abs(close_price - open_price), bottom=min(open_price, close_price), color=color, width=0.4)

        # Plot high and low wicks
        ax.vlines(date, low_price, high_price, color='black', linewidth=0.6)

        # Adjust plot aesthetics
        ax.set_xlim(date - pd.Timedelta(days=0.5), date + pd.Timedelta(days=0.5))
        ax.set_ylim(low_price - (0.05 * low_price), high_price + (0.05 * high_price))
        ax.axis('off')  # Hide axes

        # Save the figure
        image_path = os.path.join(output_folder, f"{date.strftime('%Y-%m-%d')}.png")
        plt.savefig(image_path, bbox_inches='tight', pad_inches=0.1)
        plt.close(fig)  # Close the figure to free memory

    print(f"Candlestick images successfully saved in the '{output_folder}' folder.")

except FileNotFoundError:
    print(f"Error: The file '{csv_file_path}' was not found. Please check the file path.")
except Exception as e:
    print(f"An error occurred: {e}")

import os
import pandas as pd
import matplotlib.pyplot as plt

# Define the CSV file path and check for required columns for candlestick chart
csv_file_path = 'ADANIPORTS.csv'  # Path to your stock data CSV
stock_data = pd.read_csv(csv_file_path)
required_columns = {'Date', 'Open', 'High', 'Low', 'Close'}
if not required_columns.issubset(stock_data.columns):
    raise ValueError(f"The CSV file must contain these columns: {', '.join(required_columns)}")

# Convert Date column to datetime and sort by date
stock_data['Date'] = pd.to_datetime(stock_data['Date'])
stock_data = stock_data.sort_values('Date')

# Loop through each row to plot and display candlestick images
for _, row in stock_data.iterrows():
    date = row['Date']
    open_price = row['Open']
    high_price = row['High']
    low_price = row['Low']
    close_price = row['Close']

    # Determine if the movement is up or down and set color
    movement = "Up" if close_price >= open_price else "Down"
    color = 'green' if movement == "Up" else 'red'

    # Initialize a figure and axis
    fig, ax = plt.subplots(figsize=(4, 6))  # Adjust size for better visibility

    # Plot the candlestick body
    ax.bar(date, abs(close_price - open_price), bottom=min(open_price, close_price), color=color, width=0.4)

    # Plot high and low wicks
    ax.vlines(date, low_price, high_price, color='black', linewidth=0.6)

    # Add labels for open and close prices
    ax.text(date, open_price, f'Open: {open_price}', ha='center', va='bottom', color='blue', fontsize=8)
    ax.text(date, close_price, f'Close: {close_price}', ha='center', va='top', color='purple', fontsize=8)

    # Add movement label
    ax.text(date, high_price + (0.05 * high_price), movement, ha='center', color=color, fontsize=10, weight='bold')

    # Add the date label below the candlestick
    ax.text(date, low_price - (0.1 * low_price), date.strftime('%Y-%m-%d'), ha='center', va='top', fontsize=9, color='black')

    # Set plot limits and aesthetics
    ax.set_xlim(date - pd.Timedelta(days=0.5), date + pd.Timedelta(days=0.5))
    ax.set_ylim(low_price - (0.2 * low_price), high_price + (0.1 * high_price))
    ax.axis('off')  # Hide axes for a cleaner look

    # Show the plot
    plt.show()

from google.colab import files
import zipfile
import os

# Upload the zip file
uploaded = files.upload()

# Unzip the uploaded file
for filename in uploaded.keys():
    if filename.endswith('.zip'):
        with zipfile.ZipFile(filename, 'r') as zip_ref:
            zip_ref.extractall('candlestick_images')

# List the extracted images
image_folder_path = 'candlestick_images'
print("Extracted images:")
print(os.listdir(image_folder_path))

import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing.image import load_img
import os

# Parameters
image_folder_path = 'candlestick_images'  # Folder where images are extracted
num_images_to_display = 10  # Number of images to display

# Get list of image files in the folder
image_files = sorted([f for f in os.listdir(image_folder_path) if f.endswith('.png')])

# Display a few candlestick images
plt.figure(figsize=(10, 10))
for i, image_file in enumerate(image_files[:num_images_to_display]):
    img_path = os.path.join(image_folder_path, image_file)
    img = load_img(img_path, color_mode='grayscale')

    plt.subplot(2, 5, i + 1)  # Display in a 2x5 grid for 10 images
    plt.imshow(img, cmap='gray')
    plt.axis('off')
    plt.title(image_file)

plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import os
from tensorflow.keras.preprocessing.image import load_img, img_to_array
import pandas as pd

# Parameters
image_folder_path = 'candlestick_images'
csv_file_path = 'ADANIPORTS.csv'
image_size = (64, 64)

# Load stock data
stock_data = pd.read_csv(csv_file_path)
stock_data['Date'] = pd.to_datetime(stock_data['Date'])
stock_data = stock_data[['Date', 'Close']].sort_values('Date')

# Calculate "Up" or "Down" labels based on the stock price movement
stock_data['Movement'] = stock_data['Close'].diff().apply(lambda x: 'Up' if x > 0 else 'Down')

# Display images with labels
def display_images_with_labels(image_folder, stock_data, num_images=10):
    # Sort dates to match the image order
    stock_data = stock_data.sort_values('Date')
    displayed = 0

    for index, row in stock_data.iterrows():
        date_str = row['Date'].strftime('%Y%m%d')
        image_path = os.path.join(image_folder, f"candlestick_{date_str}.png")
        label = row['Movement']

        if os.path.exists(image_path) and displayed < num_images:
            img = load_img(image_path, target_size=image_size, color_mode='grayscale')
            plt.imshow(img, cmap='gray')
            plt.title(f"Date: {row['Date'].strftime('%Y-%m-%d')} - Movement: {label}")
            plt.axis('off')
            plt.show()

            displayed += 1

# Display the first 10 images with their labels
display_images_with_labels(image_folder_path, stock_data, num_images=10)

import os

# List all files in the candlestick_images directory
image_folder_path = 'candlestick_images'
print(os.listdir(image_folder_path))

# Check the directory contents
image_folder_path = 'candlestick_images'
print("Contents of the candlestick_images directory:")
files = os.listdir(image_folder_path)
print(files)

# Example usage with a valid image path
# Update with an actual image name from the output of the directory listing
valid_image_name = '2023-01-01.png'  # Replace this with an actual image name from the list
image_path = os.path.join(image_folder_path, valid_image_name)

# Ensure the image exists before trying to predict
if valid_image_name in files:
    predicted_price = predict_stock_price(image_path)
    print(f"Predicted stock price: ${predicted_price:.2f}")
else:
    print(f"Error: The image '{valid_image_name}' does not exist in the directory.")

import os
import os
# List all files in the candlestick_images directory
image_folder_path = 'candlestick_images'
print(os.listdir(image_folder_path))

!pip install tensorflow keras pandas pillow scikit-learn

import os
import numpy as np
import pandas as pd
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split

# Define paths
image_folder_path = 'candlestick_images'  # Update this path if necessary
csv_file_path = 'ADANIPORTS.csv'  # Update this path to your stock data CSV

# Load stock data
stock_data = pd.read_csv(csv_file_path)
stock_data['Date'] = pd.to_datetime(stock_data['Date'])
stock_data = stock_data.sort_values('Date')

# Prepare image and target arrays
image_size = (64, 64)  # Resize all images to 64x64 pixels
images = []
prices = []

# Load images and corresponding prices
for i, row in stock_data.iterrows():
    date = row['Date']
    price = row['Close']
    image_path = os.path.join(image_folder_path, f"{date.strftime('%Y-%m-%d')}.png")

    if os.path.exists(image_path):
        img = load_img(image_path, target_size=image_size, color_mode='rgb')
        img_array = img_to_array(img)
        images.append(img_array)
        prices.append(price)
    else:
        print(f"Warning: Image not found for date: {date.strftime('%Y-%m-%d')}")

# Convert lists to numpy arrays
X = np.array(images)
y = np.array(prices)

# Check if any images were loaded
if len(y) == 0:
    raise ValueError("No images found for the dates in the stock data. Please check the image folder path and filenames.")

# Normalize image data and target prices
X = X / 255.0  # Normalize pixel values between 0 and 1
scaler_y = MinMaxScaler()
y = scaler_y.fit_transform(y.reshape(-1, 1)).flatten()

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Build the CNN model
model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(image_size[0], image_size[1], 3)),
    MaxPooling2D((2, 2)),
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Conv2D(128, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Flatten(),
    Dense(64, activation='relu'),
    Dense(1)  # Single output for regression (stock price)
])

# Compile the model
model.compile(optimizer='adam', loss='mse')

# Train the model
model.fit(X_train, y_train, epochs=20, batch_size=8, validation_data=(X_test, y_test))

# Function to predict stock price from a given image
def predict_stock_price(image_path):
    img = load_img(image_path, target_size=image_size, color_mode='rgb')
    img_array = img_to_array(img) / 255.0  # Normalize the image
    img_array = img_array.reshape(1, image_size[0], image_size[1], 3)  # Reshape for model input
    predicted_price_scaled = model.predict(img_array)
    predicted_price = scaler_y.inverse_transform(predicted_price_scaled)[0][0]  # Inverse transform to original price
    return predicted_price

# Example usage:
# Replace 'some_image.png' with the path to your image
predicted_price = predict_stock_price('candlestick_images/2023-01-01.png')
print(f"Predicted stock price: ${predicted_price:.2f}")

import os
import shutil

# Define the source and destination paths
source_folder = 'candlestick_images'  # Folder where your current candlestick images are located
destination_folder = 'organized_candlestick_images'  # New folder to store organized images

# Create the new directory if it doesn't exist
os.makedirs(destination_folder, exist_ok=True)

# List all files in the source directory
for filename in os.listdir(source_folder):
    if filename.endswith('.png'):  # Check for PNG images (you can modify this if needed)
        # Construct full file path
        source_file = os.path.join(source_folder, filename)
        destination_file = os.path.join(destination_folder, filename)

        # Copy the image to the new directory
        shutil.copy(source_file, destination_file)
        print(f"Copied: {filename} to {destination_folder}")

print("All candlestick images have been organized.")

import os
import shutil

# Define the source and destination paths
source_folder = 'candlestick_images'  # Folder where your current candlestick images are stored
destination_folder = 'organized_candlestick_images'  # New folder to store organized images

# Create the new directory if it doesn't exist
os.makedirs(destination_folder, exist_ok=True)

# List all files in the source directory
for filename in os.listdir(source_folder):
    if filename.endswith('.png'):  # Check for PNG images (you can modify this if needed)
        # Construct full file path
        source_file = os.path.join(source_folder, filename)
        destination_file = os.path.join(destination_folder, filename)

        # Copy the image to the new directory
        shutil.copy(source_file, destination_file)
        print(f"Copied: {filename} to {destination_folder}")

print("All candlestick images have been organized.")

# After training your model
model.save('model.h5')  # Save the model to a file named model.h5

# Import the necessary libraries (if not already imported)
from tensorflow import keras

# ... (your code to create or load the model) ...

# 1. Create a new model (example)
# model = keras.Sequential([
#     # Add your layers here
# ])

# 2. Or, load a pre-trained model
# model = keras.models.load_model('path/to/your/pretrained/model.h5')

# After training or loading your model
model.save('model.h5')  # Save the model to a file named model.h5

import os
print("Current Working Directory:", os.getcwd())

# Install necessary libraries
!pip install tensorflow keras pandas pillow scikit-learn

import os
import numpy as np
import pandas as pd
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split

# Define paths
image_folder_path = 'organized_candlestick_images'  # Update this path to your organized candlestick images
csv_file_path = 'ADANIPORTS.csv'  # Update this path to your stock data CSV
model_path = 'model.h5'  # Path for the trained model

# Load stock data for scaling
stock_data = pd.read_csv(csv_file_path)
stock_data['Date'] = pd.to_datetime(stock_data['Date'])
stock_data = stock_data.sort_values('Date')

# Initialize scaler for stock prices
scaler_y = MinMaxScaler()
scaler_y.fit(stock_data[['Close']])  # Fit the scaler to the 'Close' prices

# Check if model file exists
if not os.path.isfile(model_path):
    raise FileNotFoundError(f"The model file does not exist at the specified path: {model_path}")

# Load the trained model with custom metric
model = load_model(model_path, custom_objects={'mse': 'mean_squared_error'})

# Function to predict stock prices from images
def predict_stock_prices_from_images(image_folder):
    predictions = []
    image_size = (64, 64)  # Resize images to the same size used in training

    # Iterate through each image in the directory
    for filename in os.listdir(image_folder):
        if filename.endswith('.png'):  # Assuming your images are in PNG format
            image_path = os.path.join(image_folder, filename)

            # Load and preprocess the image
            img = load_img(image_path, target_size=image_size, color_mode='rgb')
            img_array = img_to_array(img) / 255.0  # Normalize pixel values
            img_array = img_array.reshape(1, image_size[0], image_size[1], 3)  # Reshape for model input

            # Predict the price
            predicted_price_scaled = model.predict(img_array)
            predicted_price = scaler_y.inverse_transform(predicted_price_scaled)[0][0]  # Inverse transform to original price

            # Store the prediction with the filename
            predictions.append((filename, predicted_price))
            print(f"Predicted stock price for {filename}: ${predicted_price:.2f}")

    return predictions

# Example usage
predictions = predict_stock_prices_from_images(image_folder_path)



import os
import numpy as np
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from datetime import datetime, timedelta

# Parameters
sequence_length = 10
image_size = (64, 64)  # Size used in model training
image_folder_path = 'candlestick_images'  # Folder containing candlestick images

# Prepare the last 10 days of images ending on April 30, 2021
last_date = datetime(2021, 4, 30)
dates = [last_date - timedelta(days=i) for i in reversed(range(sequence_length))]

# Load the last 10 days of images
last_10_images = []
missing_images = []
for date in dates:
    image_path = os.path.join(image_folder_path, f"candlestick_{date.strftime('%Y%m%d')}.png")

    if os.path.exists(image_path):
        img = load_img(image_path, target_size=image_size, color_mode='rgb')
        img_array = img_to_array(img)
        last_10_images.append(img_array)
    else:
        missing_images.append(date.strftime('%Y-%m-%d'))  # Log the missing image date

# Check if any images are missing
if missing_images:
    print(f"Warning: The following images are missing: {', '.join(missing_images)}")
else:
    # Convert to numpy array and normalize
    last_10_images = np.array(last_10_images) / 255.0  # Normalize
    last_10_images = last_10_images.reshape(1, sequence_length, image_size[0], image_size[1], 3)  # Reshape for model

    # Function to predict the next day's stock price
    def predict_next_day_price(last_10_images):
        predicted_price_scaled = model.predict(last_10_images)
        predicted_price = scaler_y.inverse_transform(predicted_price_scaled)[0][0]  # Inverse transform to original price
        return predicted_price

    # Predict the stock price for May 1, 2021
    predicted_price = predict_next_day_price(last_10_images)
    print(f"Predicted stock price for May 1, 2021: ${predicted_price:.2f}")

import matplotlib.pyplot as plt

# Print the number of training and testing samples
print(f"Number of training samples: {len(X_train)}")
print(f"Number of testing samples: {len(X_test)}")

# Display a few training and testing sequences
num_samples_to_display = 3

# Plot training samples
plt.figure(figsize=(10, 5))
for i in range(num_samples_to_display):
    plt.subplot(2, num_samples_to_display, i + 1)
    plt.plot(X_train[i].reshape(-1), label="Training Sequence")
    plt.title(f"Training Sample {i + 1}")
    plt.xlabel("Days")
    plt.ylabel("Normalized Price")

# Plot testing samples
for i in range(num_samples_to_display):
    plt.subplot(2, num_samples_to_display, i + 1 + num_samples_to_display)
    plt.plot(X_test[i].reshape(-1), label="Testing Sequence", color="orange")
    plt.title(f"Testing Sample {i + 1}")
    plt.xlabel("Days")
    plt.ylabel("Normalized Price")

plt.tight_layout()
plt.show()

import pandas as pd

# Load the stock data from CSV
csv_file_path = 'ADANIPORTS.csv'  # Replace with the actual path to your CSV file
stock_data = pd.read_csv(csv_file_path)

# Convert the 'Date' column to datetime format
stock_data['Date'] = pd.to_datetime(stock_data['Date'])

# Filter the data for April 30, 2021
april_30_data = stock_data[stock_data['Date'] == '2021-04-30']

# Check if data for April 30, 2021, is available
if not april_30_data.empty:
    # Get the closing price for April 30, 2021
    april_30_price = april_30_data['Close'].values[0]
    print(f"Stock price on April 30, 2021: ${april_30_price:.2f}")
else:
    print("No data available for April 30, 2021.")

import numpy as np
import pandas as pd
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from sklearn.preprocessing import MinMaxScaler
from datetime import datetime, timedelta

# Load stock data
csv_file_path = 'ADANIPORTS.csv'  # Path to your stock data CSV
stock_data = pd.read_csv(csv_file_path)
stock_data['Date'] = pd.to_datetime(stock_data['Date'])
stock_data = stock_data[['Date', 'Close']]  # Using Date and Close columns

# Normalize the stock prices using MinMaxScaler
scaler_y = MinMaxScaler(feature_range=(0, 1))
stock_data['Close'] = scaler_y.fit_transform(stock_data[['Close']])

# Prepare the dataset: Use the last 10 days' stock prices to predict the next day
sequence_length = 10  # Use the last 10 days' stock prices to predict the next day
def prepare_data(stock_data, sequence_length):
    X = []
    y = []

    for i in range(len(stock_data) - sequence_length):
        X.append(stock_data['Close'].iloc[i:i + sequence_length].values)
        y.append(stock_data['Close'].iloc[i + sequence_length])  # The next day's price

    X = np.array(X)
    y = np.array(y)

    return X, y

# Prepare the data for training
X, y = prepare_data(stock_data, sequence_length)

# Reshape X for LSTM input
X = X.reshape((X.shape[0], X.shape[1], 1))  # (samples, time steps, features)

# Split the data into training and test sets
train_size = int(len(X) * 0.8)
X_train, X_test = X[:train_size], X[train_size:]
y_train, y_test = y[:train_size], y[train_size:]

# Build the LSTM model
model = Sequential([
    LSTM(50, return_sequences=True, input_shape=(sequence_length, 1)),
    LSTM(50),
    Dense(1)
])

model.compile(optimizer='adam', loss='mean_squared_error')

# Train the model
model.fit(X_train, y_train, epochs=20, batch_size=32)

# Make predictions for the test set (to evaluate model)
predictions = model.predict(X_test)

# Inverse scaling to get the predicted price back to original scale
predictions = scaler_y.inverse_transform(predictions)
y_test_actual = scaler_y.inverse_transform(y_test.reshape(-1, 1))

# Print predictions for May 1, 2021 (last date)
predicted_price = predictions[-1][0]
print(f"Predicted stock price for May 1, 2021: ${predicted_price:.2f}")

import os
import numpy as np
import pandas as pd
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from sklearn.preprocessing import MinMaxScaler
from datetime import datetime, timedelta
import matplotlib.pyplot as plt

# Load stock data
csv_file_path = 'ADANIPORTS.csv'  # Path to your stock data CSV
stock_data = pd.read_csv(csv_file_path)
stock_data['Date'] = pd.to_datetime(stock_data['Date'])
stock_data = stock_data[['Date', 'Close']]  # Using Date and Close columns

# Sort by date
stock_data = stock_data.sort_values('Date')

# Normalize the stock prices using MinMaxScaler
scaler_y = MinMaxScaler(feature_range=(0, 1))
stock_data['Close'] = scaler_y.fit_transform(stock_data[['Close']])

# Prepare the dataset: Use the last 10 days' stock prices to predict the next day
sequence_length = 10  # Use the last 10 days' stock prices to predict the next day
def prepare_data(stock_data, sequence_length):
    X = []
    y = []

    for i in range(len(stock_data) - sequence_length):
        X.append(stock_data['Close'].iloc[i:i + sequence_length].values)
        y.append(stock_data['Close'].iloc[i + sequence_length])  # The next day's price

    X = np.array(X)
    y = np.array(y)

    return X, y

# Prepare the data for training
X, y = prepare_data(stock_data, sequence_length)

# Reshape X for LSTM input
X = X.reshape((X.shape[0], X.shape[1], 1))  # (samples, time steps, features)

# Split the data into training and test sets
train_size = int(len(X) * 0.8)
X_train, X_test = X[:train_size], X[train_size:]
y_train, y_test = y[:train_size], y[train_size:]

# Build the LSTM model
model = Sequential([
    LSTM(50, return_sequences=True, input_shape=(sequence_length, 1)),
    LSTM(50),
    Dense(1)
])

model.compile(optimizer='adam', loss='mean_squared_error')

# Train the model
model.fit(X_train, y_train, epochs=20, batch_size=32)

# Make predictions for the test set (to evaluate model)
predictions = model.predict(X_test)

# Inverse scaling to get the predicted price back to original scale
predictions = scaler_y.inverse_transform(predictions)
y_test_actual = scaler_y.inverse_transform(y_test.reshape(-1, 1))

# Print predictions for May 1, 2021 (last date)
predicted_price = predictions[-1][0]
print(f"Predicted stock price for May 1, 2021: ${predicted_price:.2f}")

# Plot predictions vs actual values
plt.figure(figsize=(10,6))
plt.plot(y_test_actual, label='Actual Price')
plt.plot(predictions, label='Predicted Price')
plt.legend()
plt.show()

import os
import numpy as np
import pandas as pd
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Conv2D, MaxPooling2D, Flatten, TimeDistributed
from sklearn.preprocessing import MinMaxScaler
from datetime import datetime, timedelta
import matplotlib.pyplot as plt

# Load stock data
csv_file_path = 'ADANIPORTS.csv'  # Path to your stock data CSV
stock_data = pd.read_csv(csv_file_path)
stock_data['Date'] = pd.to_datetime(stock_data['Date'])
stock_data = stock_data[['Date', 'Close']]  # Using Date and Close columns
stock_data = stock_data.sort_values('Date')

# Normalize the stock prices using MinMaxScaler
scaler_y = MinMaxScaler(feature_range=(0, 1))
stock_data['Close'] = scaler_y.fit_transform(stock_data[['Close']])

# Prepare the dataset: Use the last 10 days' stock prices to predict the next day
sequence_length = 10  # Use the last 10 days' stock prices to predict the next day
def prepare_data(stock_data, sequence_length):
    X = []
    y = []

    for i in range(len(stock_data) - sequence_length):
        X.append(stock_data['Close'].iloc[i:i + sequence_length].values)
        y.append(stock_data['Close'].iloc[i + sequence_length])  # The next day's price

    X = np.array(X)
    y = np.array(y)

    return X, y

# Prepare the data for training
X, y = prepare_data(stock_data, sequence_length)

# Reshape X for LSTM input
X = X.reshape((X.shape[0], X.shape[1], 1))  # (samples, time steps, features)

# Split the data into training and test sets
train_size = int(len(X) * 0.8)
X_train, X_test = X[:train_size], X[train_size:]
y_train, y_test = y[:train_size], y[train_size:]

# Build the LSTM model
lstm_model = Sequential([
    LSTM(50, return_sequences=True, input_shape=(sequence_length, 1)),
    LSTM(50),
    Dense(1)
])

lstm_model.compile(optimizer='adam', loss='mean_squared_error')

# Train the LSTM model
lstm_model.fit(X_train, y_train, epochs=20, batch_size=32)

# Make predictions for the last day in the test set
lstm_predictions = lstm_model.predict(X_test)
lstm_predictions = scaler_y.inverse_transform(lstm_predictions)

# Build the CNN-LSTM model using the same stock price input
# Reshape X for CNN-LSTM input: add a new axis for channels
X_cnn_lstm = X.reshape((X.shape[0], X.shape[1], 1, 1))  # (samples, time steps, height, width)

# Build the CNN-LSTM model
cnn_lstm_model = Sequential([
    TimeDistributed(Conv2D(32, (1, 1), activation='relu'), input_shape=(sequence_length, 1, 1, 1)),  # Only prices
    TimeDistributed(MaxPooling2D((1, 1))),
    TimeDistributed(Flatten()),
    LSTM(50, return_sequences=False),
    Dense(1)
])

cnn_lstm_model.compile(optimizer='adam', loss='mean_squared_error')

# Train the CNN-LSTM model
cnn_lstm_model.fit(X_cnn_lstm[:train_size], y_train, epochs=20, batch_size=32)

# Make predictions for the last day in the test set
cnn_lstm_predictions = cnn_lstm_model.predict(X_cnn_lstm[train_size:])
cnn_lstm_predictions = scaler_y.inverse_transform(cnn_lstm_predictions)

# Compare predictions
predicted_price_lstm = lstm_predictions[-1][0]
predicted_price_cnn_lstm = cnn_lstm_predictions[-1][0]

print(f"Predicted stock price (LSTM) for May 1, 2021: ${predicted_price_lstm:.2f}")
print(f"Predicted stock price (CNN-LSTM) for May 1, 2021: ${predicted_price_cnn_lstm:.2f}")

# Plot predictions vs actual values
plt.figure(figsize=(10, 6))
plt.plot(y_test, label='Actual Price', color='blue')
plt.plot(lstm_predictions, label='LSTM Predicted Price', color='red')
plt.plot(cnn_lstm_predictions, label='CNN-LSTM Predicted Price', color='green')
plt.legend()
plt.title('Stock Price Prediction')
plt.xlabel('Days')
plt.ylabel('Stock Price')
plt.show()

import os
import numpy as np
import pandas as pd
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Conv2D, MaxPooling2D, Flatten, TimeDistributed
from sklearn.preprocessing import MinMaxScaler
from datetime import datetime, timedelta
import matplotlib.pyplot as plt

# Load stock data
csv_file_path = 'ADANIPORTS.csv'  # Path to your stock data CSV
stock_data = pd.read_csv(csv_file_path)
stock_data['Date'] = pd.to_datetime(stock_data['Date'])
stock_data = stock_data[['Date', 'Close']]  # Using Date and Close columns
stock_data = stock_data.sort_values('Date')

# Normalize the stock prices using MinMaxScaler
scaler_y = MinMaxScaler(feature_range=(0, 1))
stock_data['Close'] = scaler_y.fit_transform(stock_data[['Close']])

# Prepare the dataset: Use the last 10 days' stock prices to predict the next day
sequence_length = 10  # Use the last 10 days' stock prices to predict the next day
def prepare_data(stock_data, sequence_length):
    X = []
    y = []

    for i in range(len(stock_data) - sequence_length):
        X.append(stock_data['Close'].iloc[i:i + sequence_length].values)
        y.append(stock_data['Close'].iloc[i + sequence_length])  # The next day's price

    X = np.array(X)
    y = np.array(y)

    return X, y

# Prepare the data for training
X, y = prepare_data(stock_data, sequence_length)

# Reshape X for LSTM input
X = X.reshape((X.shape[0], X.shape[1], 1))  # (samples, time steps, features)

# Split the data into training and test sets
train_size = int(len(X) * 0.8)
X_train, X_test = X[:train_size], X[train_size:]
y_train, y_test = y[:train_size], y[train_size:]

# Build the LSTM model
lstm_model = Sequential([
    LSTM(50, return_sequences=True, input_shape=(sequence_length, 1)),
    LSTM(50),
    Dense(1)
])

lstm_model.compile(optimizer='adam', loss='mean_squared_error')

# Train the LSTM model
lstm_model.fit(X_train, y_train, epochs=20, batch_size=32)

# Make predictions for the last day in the test set
lstm_predictions = lstm_model.predict(X_test)
lstm_predictions = scaler_y.inverse_transform(lstm_predictions)

# Build the CNN-LSTM model using the same stock price input
# Reshape X for CNN-LSTM input: add a new axis for channels
X_cnn_lstm = X.reshape((X.shape[0], X.shape[1], 1, 1))  # (samples, time steps, height, width)

# Build the CNN-LSTM model
cnn_lstm_model = Sequential([
    TimeDistributed(Conv2D(32, (1, 1), activation='relu'), input_shape=(sequence_length, 1, 1, 1)),  # Only prices
    TimeDistributed(MaxPooling2D((1, 1))),
    TimeDistributed(Flatten()),
    LSTM(50, return_sequences=False),
    Dense(1)
])

cnn_lstm_model.compile(optimizer='adam', loss='mean_squared_error')

# Train the CNN-LSTM model
cnn_lstm_model.fit(X_cnn_lstm[:train_size], y_train, epochs=20, batch_size=32)

# Make predictions for the last day in the test set
cnn_lstm_predictions = cnn_lstm_model.predict(X_cnn_lstm[train_size:])
cnn_lstm_predictions = scaler_y.inverse_transform(cnn_lstm_predictions)

# Compare predictions
predicted_price_lstm = lstm_predictions[-1][0]
predicted_price_cnn_lstm = cnn_lstm_predictions[-1][0]

print(f"Predicted stock price (LSTM) for May 1, 2021: ${predicted_price_lstm:.2f}")
print(f"Predicted stock price (CNN-LSTM) for May 1, 2021: ${predicted_price_cnn_lstm:.2f}")

# Plot predictions vs actual values
plt.figure(figsize=(10, 6))
plt.plot(y_test, label='Actual Price', color='blue')
plt.plot(lstm_predictions, label='LSTM Predicted Price', color='red')
plt.plot(cnn_lstm_predictions, label='CNN-LSTM Predicted Price', color='green')
plt.legend()
plt.title('Stock Price Prediction')
plt.xlabel('Days')
plt.ylabel('Stock Price')
plt.show()

import os
import numpy as np
import pandas as pd
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Conv2D, MaxPooling2D, Flatten, TimeDistributed
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_percentage_error
import matplotlib.pyplot as plt

# Load stock data
csv_file_path = 'ADANIPORTS.csv'  # Path to your stock data CSV
stock_data = pd.read_csv(csv_file_path)
stock_data['Date'] = pd.to_datetime(stock_data['Date'])
stock_data = stock_data[['Date', 'Close']]  # Using Date and Close columns
stock_data = stock_data.sort_values('Date')

# Normalize the stock prices using MinMaxScaler
scaler_y = MinMaxScaler(feature_range=(0, 1))
stock_data['Close'] = scaler_y.fit_transform(stock_data[['Close']])

# Prepare the dataset: Use the last 10 days' stock prices to predict the next day
sequence_length = 10  # Use the last 10 days' stock prices to predict the next day
def prepare_data(stock_data, sequence_length):
    X = []
    y = []

    for i in range(len(stock_data) - sequence_length):
        X.append(stock_data['Close'].iloc[i:i + sequence_length].values)
        y.append(stock_data['Close'].iloc[i + sequence_length])  # The next day's price

    X = np.array(X)
    y = np.array(y)

    return X, y

# Prepare the data for training
X, y = prepare_data(stock_data, sequence_length)

# Reshape X for LSTM input
X = X.reshape((X.shape[0], X.shape[1], 1))  # (samples, time steps, features)

# Split the data into training and test sets
train_size = int(len(X) * 0.8)
X_train, X_test = X[:train_size], X[train_size:]
y_train, y_test = y[:train_size], y[train_size:]

# Build the LSTM model
lstm_model = Sequential([
    LSTM(50, return_sequences=True, input_shape=(sequence_length, 1)),
    LSTM(50),
    Dense(1)
])

lstm_model.compile(optimizer='adam', loss='mean_squared_error')

# Train the LSTM model
lstm_model.fit(X_train, y_train, epochs=20, batch_size=32, verbose=0)

# Make predictions for the test set
lstm_predictions = lstm_model.predict(X_test)
lstm_predictions = scaler_y.inverse_transform(lstm_predictions)
y_test_actual = scaler_y.inverse_transform(y_test.reshape(-1, 1))

# Build the CNN-LSTM model using the same stock price input
# Reshape X for CNN-LSTM input: add a new axis for channels
X_cnn_lstm = X.reshape((X.shape[0], X.shape[1], 1, 1))  # (samples, time steps, height, width)

# Build the CNN-LSTM model
cnn_lstm_model = Sequential([
    TimeDistributed(Conv2D(32, (1, 1), activation='relu'), input_shape=(sequence_length, 1, 1, 1)),  # Only prices
    TimeDistributed(MaxPooling2D((1, 1))),
    TimeDistributed(Flatten()),
    LSTM(50, return_sequences=False),
    Dense(1)
])

cnn_lstm_model.compile(optimizer='adam', loss='mean_squared_error')

# Train the CNN-LSTM model
cnn_lstm_model.fit(X_cnn_lstm[:train_size], y_train, epochs=20, batch_size=32, verbose=0)

# Make predictions for the test set
cnn_lstm_predictions = cnn_lstm_model.predict(X_cnn_lstm[train_size:])
cnn_lstm_predictions = scaler_y.inverse_transform(cnn_lstm_predictions)

# Calculate Mean Absolute Percentage Error (MAPE) for both models
lstm_mape = mean_absolute_percentage_error(y_test_actual, lstm_predictions) * 100
cnn_lstm_mape = mean_absolute_percentage_error(y_test_actual, cnn_lstm_predictions) * 100

print(f"LSTM Model MAPE: {lstm_mape:.2f}%")
print(f"CNN-LSTM Model MAPE: {cnn_lstm_mape:.2f}%")

# Calculate the difference between the LSTM and CNN-LSTM predicted prices
price_difference = np.abs(lstm_predictions - cnn_lstm_predictions)

# Calculate Mean Absolute Error (MAE) for the difference
mae_difference = np.mean(price_difference)
print(f"Mean Absolute Error between LSTM and CNN-LSTM predictions: {mae_difference:.4f}")

# Plot the stock prices for both models and the difference
plt.figure(figsize=(12, 6))

# Plot Actual vs LSTM predicted prices
plt.subplot(2, 1, 1)
plt.plot(y_test_actual, label='Actual Price', color='blue')
plt.plot(lstm_predictions, label='LSTM Predicted Price', color='red', linestyle='dashed')
plt.plot(cnn_lstm_predictions, label='CNN-LSTM Predicted Price', color='green', linestyle='dotted')
plt.legend()
plt.title('Stock Price Prediction Comparison (LSTM vs CNN-LSTM)')
plt.xlabel('Days')
plt.ylabel('Stock Price')

# Plot the difference between LSTM and CNN-LSTM predictions
plt.subplot(2, 1, 2)
plt.plot(price_difference, label='Price Difference (LSTM vs CNN-LSTM)', color='purple')
plt.legend()
plt.title('Difference in Predicted Prices (LSTM vs CNN-LSTM)')
plt.xlabel('Days')
plt.ylabel('Price Difference')

plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split

# Helper function to create and train LSTM models with different configurations
def train_lstm_model(X_train, y_train, X_test, y_test, sequence_length, epochs, batch_size, units):
    model = Sequential([
        LSTM(units, return_sequences=True, input_shape=(sequence_length, 1)),
        LSTM(units),
        Dense(1)
    ])
    model.compile(optimizer='adam', loss='mean_squared_error')
    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=0)

    # Make predictions and inverse transform
    lstm_predictions = model.predict(X_test)
    lstm_predictions = scaler_y.inverse_transform(lstm_predictions)
    y_test_actual = scaler_y.inverse_transform(y_test.reshape(-1, 1))

    # Calculate MAPE
    lstm_mape = mean_absolute_percentage_error(y_test_actual, lstm_predictions) * 100
    return lstm_predictions, lstm_mape

# Helper function to create and train CNN-LSTM models with different configurations
def train_cnn_lstm_model(X_train, y_train, X_test, y_test, sequence_length, epochs, batch_size, units):
    X_cnn_lstm = X_train.reshape((X_train.shape[0], X_train.shape[1], 1, 1))

    model = Sequential([
        TimeDistributed(Conv2D(32, (1, 1), activation='relu'), input_shape=(sequence_length, 1, 1, 1)),
        TimeDistributed(MaxPooling2D((1, 1))),
        TimeDistributed(Flatten()),
        LSTM(units, return_sequences=False),
        Dense(1)
    ])
    model.compile(optimizer='adam', loss='mean_squared_error')
    model.fit(X_cnn_lstm, y_train, epochs=epochs, batch_size=batch_size, verbose=0)

    # Reshape test data for CNN-LSTM input
    X_cnn_lstm_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1, 1))
    cnn_lstm_predictions = model.predict(X_cnn_lstm_test)
    cnn_lstm_predictions = scaler_y.inverse_transform(cnn_lstm_predictions)
    y_test_actual = scaler_y.inverse_transform(y_test.reshape(-1, 1))

    # Calculate MAPE
    cnn_lstm_mape = mean_absolute_percentage_error(y_test_actual, cnn_lstm_predictions) * 100
    return cnn_lstm_predictions, cnn_lstm_mape

# Experiment 1: Varying sequence length
sequence_lengths = [5, 10, 20]
lstm_mapes = []
cnn_lstm_mapes = []
for seq_len in sequence_lengths:
    X, y = prepare_data(stock_data, seq_len)
    X = X.reshape((X.shape[0], X.shape[1], 1))  # (samples, time steps, features)

    # Split the data
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)

    lstm_predictions, lstm_mape = train_lstm_model(X_train, y_train, X_test, y_test, seq_len, epochs=20, batch_size=32, units=50)
    cnn_lstm_predictions, cnn_lstm_mape = train_cnn_lstm_model(X_train, y_train, X_test, y_test, seq_len, epochs=20, batch_size=32, units=50)

    lstm_mapes.append(lstm_mape)
    cnn_lstm_mapes.append(cnn_lstm_mape)

# Plot the results of different sequence lengths
plt.figure(figsize=(10, 6))
plt.plot(sequence_lengths, lstm_mapes, label='LSTM Model MAPE', marker='o')
plt.plot(sequence_lengths, cnn_lstm_mapes, label='CNN-LSTM Model MAPE', marker='o')
plt.title('MAPE vs Sequence Length')
plt.xlabel('Sequence Length')
plt.ylabel('MAPE (%)')
plt.legend()
plt.show()

# Experiment 2: Varying batch size
batch_sizes = [16, 32, 64]
lstm_mapes_batch = []
cnn_lstm_mapes_batch = []
for batch_size in batch_sizes:
    lstm_predictions, lstm_mape = train_lstm_model(X_train, y_train, X_test, y_test, sequence_length=10, epochs=20, batch_size=batch_size, units=50)
    cnn_lstm_predictions, cnn_lstm_mape = train_cnn_lstm_model(X_train, y_train, X_test, y_test, sequence_length=10, epochs=20, batch_size=batch_size, units=50)

    lstm_mapes_batch.append(lstm_mape)
    cnn_lstm_mapes_batch.append(cnn_lstm_mape)

# Plot the results of different batch sizes
plt.figure(figsize=(10, 6))
plt.plot(batch_sizes, lstm_mapes_batch, label='LSTM Model MAPE', marker='o')
plt.plot(batch_sizes, cnn_lstm_mapes_batch, label='CNN-LSTM Model MAPE', marker='o')
plt.title('MAPE vs Batch Size')
plt.xlabel('Batch Size')
plt.ylabel('MAPE (%)')
plt.legend()
plt.show()

# Experiment 3: Varying the number of epochs
epochs_list = [10, 20, 50]
lstm_mapes_epochs = []
cnn_lstm_mapes_epochs = []
for epochs in epochs_list:
    lstm_predictions, lstm_mape = train_lstm_model(X_train, y_train, X_test, y_test, sequence_length=10, epochs=epochs, batch_size=32, units=50)
    cnn_lstm_predictions, cnn_lstm_mape = train_cnn_lstm_model(X_train, y_train, X_test, y_test, sequence_length=10, epochs=epochs, batch_size=32, units=50)

    lstm_mapes_epochs.append(lstm_mape)
    cnn_lstm_mapes_epochs.append(cnn_lstm_mape)

# Plot the results of different epochs
plt.figure(figsize=(10, 6))
plt.plot(epochs_list, lstm_mapes_epochs, label='LSTM Model MAPE', marker='o')
plt.plot(epochs_list, cnn_lstm_mapes_epochs, label='CNN-LSTM Model MAPE', marker='o')
plt.title('MAPE vs Number of Epochs')
plt.xlabel('Number of Epochs')
plt.ylabel('MAPE (%)')
plt.legend()
plt.show()

# Required Libraries
!pip install tensorflow keras pandas scikit-learn Pillow

import os
import numpy as np
import pandas as pd
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, LSTM, Dense, TimeDistributed, Input, Concatenate
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from sklearn.preprocessing import MinMaxScaler
import matplotlib.pyplot as plt

# Parameters
sequence_length = 15  # Use last 15 days for prediction
image_size = (64, 64)
image_folder_path = 'candlestick_images'
csv_file_path = 'ADANIPORTS.csv'
target_date = '2021-05-01'

# Load stock data
stock_data = pd.read_csv(csv_file_path)
stock_data['Date'] = pd.to_datetime(stock_data['Date'])
stock_data = stock_data[['Date', 'Close']].sort_values('Date')

# Normalize stock prices
scaler_y = MinMaxScaler(feature_range=(0, 1))
stock_data['Close'] = scaler_y.fit_transform(stock_data[['Close']])

# Prepare sequential data for stock prices (LSTM Model)
prices = stock_data['Close'].values
price_sequences = []

for i in range(len(prices) - sequence_length):
    price_sequences.append(prices[i:i + sequence_length + 1])

price_sequences = np.array(price_sequences)
X_price = price_sequences[:, :-1].reshape(-1, sequence_length, 1)
y_price = price_sequences[:, -1]

# Split data into training and testing sets for price-only model
train_size = int(len(X_price) * 0.8)
X_train_price, X_test_price = X_price[:train_size], X_price[train_size:]
y_train_price, y_test_price = y_price[:train_size], y_price[train_size:]

# Define LSTM model for stock prices only
price_input = Input(shape=(sequence_length, 1))
x = LSTM(50, return_sequences=True)(price_input)
x = LSTM(50)(x)
price_output = Dense(1)(x)
price_model = Model(inputs=price_input, outputs=price_output)

price_model.compile(optimizer='adam', loss='mean_squared_error')
price_model.fit(X_train_price, y_train_price, epochs=10, batch_size=32, verbose=1)

# Prepare image sequences
dates = stock_data['Date'].values

def load_images_sequence(dates, folder_path=image_folder_path):
    images = []
    for date in dates:
        date_str = pd.to_datetime(date).strftime('%Y%m%d')
        image_path = os.path.join(folder_path, f"candlestick_{date_str}.png")

        if os.path.exists(image_path):
            img = load_img(image_path, target_size=image_size, color_mode='grayscale')
            img_array = img_to_array(img) / 255.0
            images.append(img_array)
        else:
            images.append(np.zeros((image_size[0], image_size[1], 1)))  # Black image if missing
    return np.array(images)

# Create sequences for CNN-LSTM model
image_sequences, y_image_sequences = [], []

for i in range(len(dates) - sequence_length):
    image_dates = dates[i:i + sequence_length]
    image_sequences.append(load_images_sequence(image_dates))
    y_image_sequences.append(prices[i + sequence_length])  # Predict next day's price

image_sequences = np.array(image_sequences)
y_image_sequences = np.array(y_image_sequences)

# Split into training and testing sets for CNN-LSTM model
X_train_images, X_test_images = image_sequences[:train_size], image_sequences[train_size:]
y_train_images, y_test_images = y_image_sequences[:train_size], y_image_sequences[train_size:]

# Define CNN-LSTM model for images
image_input = Input(shape=(sequence_length, image_size[0], image_size[1], 1))
y = TimeDistributed(Conv2D(32, (3, 3), activation='relu'))(image_input)
y = TimeDistributed(MaxPooling2D((2, 2)))(y)
y = TimeDistributed(Conv2D(64, (3, 3), activation='relu'))(y)
y = TimeDistributed(MaxPooling2D((2, 2)))(y)
y = TimeDistributed(Flatten())(y)
y = LSTM(50, activation='relu')(y)
image_output = Dense(1)(y)
cnn_lstm_model = Model(inputs=image_input, outputs=image_output)

cnn_lstm_model.compile(optimizer='adam', loss='mean_squared_error')
cnn_lstm_model.fit(X_train_images, y_train_images, epochs=10, batch_size=32, verbose=1)

# Hybrid model: Combine CNN-LSTM and LSTM outputs
combined_output = Concatenate()([price_output, image_output])
combined_output = Dense(1)(combined_output)
hybrid_model = Model(inputs=[price_input, image_input], outputs=combined_output)

hybrid_model.compile(optimizer='adam', loss='mean_squared_error')
hybrid_model.fit([X_train_price, X_train_images], y_train_images, epochs=10, batch_size=32, verbose=1)

# Use the last available 15-day sequence for prediction
last_sequence_index = len(X_price) - 1
target_sequence_prices = X_price[last_sequence_index].reshape(1, sequence_length, 1)
last_image_sequence = image_sequences[-1].reshape(1, sequence_length, image_size[0], image_size[1], 1)

# Prediction with Hybrid Model
predicted_price_scaled = hybrid_model.predict([target_sequence_prices, last_image_sequence])
predicted_price_hybrid = scaler_y.inverse_transform(predicted_price_scaled.reshape(-1, 1))[0][0]

print(f"Predicted stock price for {target_date} using Hybrid Model: ${predicted_price_hybrid:.2f}")

# Install SHAP if you havent already
!pip install shap



def prediction_justification():
    justification_text = """
    # Stock Price Prediction Justification

    The stock price prediction in this model is based on a combination of historical stock prices and candlestick chart images, as explained below:

    1. **Historical Stock Prices**:
       - **Sequence Length**: The model considers the last 15 days of closing prices to make the next day's price prediction. This 15-day sequence provides recent trends and patterns that influence the future price.
       - **Normalization**: The stock prices are normalized between 0 and 1. This scaling process ensures that all values are treated equally by the model, preventing any single high-value data point from dominating the learning.
       - **LSTM Layers**: The price data is processed through Long Short-Term Memory (LSTM) layers, which are effective for learning patterns in sequential data over time. The LSTM model can capture temporal relationships, trends, and seasonality in the stock prices.

    2. **Candlestick Chart Images**:
       - **Image Data**: Each day in the 15-day sequence has an associated candlestick chart image representing that day's price movements (open, high, low, and close). These images capture visual patterns in price behavior, like uptrends, downtrends, and consolidation patterns.
       - **Image Dimensions**: The images are resized to 64x64 pixels and converted to grayscale. This resizing helps reduce computational complexity while retaining key pattern information.
       - **CNN-LSTM Layers**: The model uses Convolutional Neural Network (CNN) layers to extract spatial features from each image. Then, the TimeDistributed wrapper applies CNN layers across each day in the 15-day sequence to detect temporal visual patterns, while the LSTM layer captures sequential relationships over time.

    3. **Hybrid Model**:
       - **Combined Features**: The outputs from the price LSTM model and the CNN-LSTM model (for images) are combined in a hybrid model. This approach integrates both the numerical price trends and the visual information in the candlestick patterns, aiming to improve prediction accuracy.
       - **Dense Layer Output**: After combining these features, the hybrid model outputs a single predicted stock price for the next day.

    ### Prediction Target
    - **Target Day Prediction**: The model's final output predicts the stock's closing price for the day immediately following the last day in the 15-day sequence.
    - **Inverse Transformation**: The prediction is scaled back to the original price range, making it directly interpretable.

    ### Training and Evaluation
    - **Mean Squared Error (MSE)**: The model uses MSE as its loss function, penalizing large deviations from the actual price. It was trained on 80% of the data and tested on 20% to ensure accuracy and generalization.

    ### Summary
    This hybrid approach utilizes both sequential price data and visual chart patterns, providing a more comprehensive understanding of stock movements than relying on price or images alone.
    """

    # Print the justification text
    print(justification_text)

# Call the function to print the justification
prediction_justification()

import pandas as pd
import os

# Load the dataset and define parameters
csv_file_path = 'ADANIPORTS.csv'
image_folder_path = 'candlestick_images'
sequence_length = 15  # 15 days for the sequence

# Load stock data
stock_data = pd.read_csv(csv_file_path)
stock_data['Date'] = pd.to_datetime(stock_data['Date'])
stock_data = stock_data[['Date', 'Close']].sort_values('Date')

def prediction_justification(stock_data, image_folder_path, sequence_length):
    # Basic info from the dataset
    start_date = stock_data['Date'].iloc[0].strftime('%Y-%m-%d')
    end_date = stock_data['Date'].iloc[-1].strftime('%Y-%m-%d')
    total_days = len(stock_data)
    avg_price = stock_data['Close'].mean()
    last_15_days = stock_data.tail(sequence_length)

    # Count available images
    available_images = sum(
        1 for date in last_15_days['Date']
        if os.path.exists(os.path.join(image_folder_path, f"candlestick_{date.strftime('%Y%m%d')}.png"))
    )

    justification_text = f"""
    # Stock Price Prediction Justification

    The stock price prediction in this model is based on a hybrid approach, combining historical stock prices with candlestick chart images. Here is a detailed justification:

    1. **Historical Stock Prices (Dataset)**:
       - **Data Range**: The dataset spans from {start_date} to {end_date}, covering {total_days} days of stock prices.
       - **Sequence Length**: The model uses the last 15 days' closing prices to predict the next days closing price. These 15 days of historical prices provide recent trends, which are crucial for the model to learn temporal dependencies.
       - **Average Stock Price**: The average stock price during this period is approximately ${avg_price:.2f}.
       - **LSTM Layers**: The LSTM network is designed to capture time-dependent patterns, such as trends and seasonality in the stock price data, improving the models ability to make sequential predictions.

    2. **Candlestick Chart Images (Visual Data)**:
       - **Image Data**: The model processes candlestick chart images that represent each days open, high, low, and close prices visually. Each image reflects the price movement patterns for that day.
       - **Images for Sequence**: Out of the last 15 days used in the sequence, {available_images} candlestick chart images were available in the image dataset. These images enhance the prediction by capturing visual trends that may not be as apparent in numerical data.
       - **Image Dimensions**: Each image is resized to 64x64 pixels and converted to grayscale, capturing essential visual features while keeping computational requirements manageable.
       - **CNN-LSTM Layers**: Convolutional layers (CNN) extract spatial features from each image, while LSTM layers handle the time-based sequence of these features across 15 days.

    3. **Hybrid Model (Combined Approach)**:
       - **Feature Combination**: The outputs from both the price-only LSTM model and the image-based CNN-LSTM model are combined in a hybrid model. This approach merges insights from the numerical price data and visual candlestick patterns, aiming to increase prediction accuracy by leveraging multiple perspectives.
       - **Target Prediction**: The hybrid model predicts the stocks closing price for the next day following the last day in the sequence. This output provides a price estimate for the immediate future based on the most recent 15 days of both price and image data.

    ### Summary
    The prediction is made by integrating both sequential stock price data and visual chart data. This dual approach enriches the models understanding, potentially capturing complex patterns that are present in both numerical and visual formats.
    """

    # Print the justification text
    print(justification_text)

# Call the function to print the justification
prediction_justification(stock_data, image_folder_path, sequence_length)

from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import numpy as np

# Make predictions on the test set
y_pred = hybrid_model.predict([X_test_price, X_test_images])

# Inverse transform predictions and actual values to original scale
y_pred_rescaled = scaler_y.inverse_transform(y_pred)
y_test_rescaled = scaler_y.inverse_transform(y_test_images.reshape(-1, 1))

# Calculate regression metrics
mae = mean_absolute_error(y_test_rescaled, y_pred_rescaled)
mse = mean_squared_error(y_test_rescaled, y_pred_rescaled)
rmse = np.sqrt(mse)
r2 = r2_score(y_test_rescaled, y_pred_rescaled)

# Print the results
print(f"Mean Absolute Error (MAE): {mae:.2f}")
print(f"Mean Squared Error (MSE): {mse:.2f}")
print(f"Root Mean Squared Error (RMSE): {rmse:.2f}")
print(f"R Score: {r2:.2f}")

from sklearn.metrics import mean_absolute_error, mean_squared_error

# Prediction on test data
predicted_prices_scaled = hybrid_model.predict([X_test_price, X_test_images])
predicted_prices = scaler_y.inverse_transform(predicted_prices_scaled.reshape(-1, 1)).flatten()
actual_prices = scaler_y.inverse_transform(y_test_images.reshape(-1, 1)).flatten()

# Calculate accuracy metrics
mae = mean_absolute_error(actual_prices, predicted_prices)
mse = mean_squared_error(actual_prices, predicted_prices)
rmse = np.sqrt(mse)

print(f"Mean Absolute Error (MAE): {mae:.4f}")
print(f"Mean Squared Error (MSE): {mse:.4f}")
print(f"Root Mean Squared Error (RMSE): {rmse:.4f}")

# Optional: Plot actual vs predicted prices for a visual assessment
plt.figure(figsize=(12, 6))
plt.plot(actual_prices, label="Actual Prices", color="blue")
plt.plot(predicted_prices, label="Predicted Prices", color="red")
plt.title("Actual vs Predicted Stock Prices")
plt.xlabel("Time Step")
plt.ylabel("Stock Price")
plt.legend()
plt.show()

import numpy as np
import matplotlib.pyplot as plt

# Predict stock prices using the trained LSTM model
lstm_predicted_prices = price_model.predict(X_test_price)
lstm_predicted_prices = scaler_y.inverse_transform(lstm_predicted_prices)  # Rescale to original price

# Predict stock prices using the trained Hybrid CNN-LSTM model
hybrid_predicted_prices = hybrid_model.predict([X_test_price, X_test_images])
hybrid_predicted_prices = scaler_y.inverse_transform(hybrid_predicted_prices)  # Rescale to original price

# Rescale actual prices back to original scale
actual_prices = scaler_y.inverse_transform(y_test_price.reshape(-1, 1))

# Flatten the arrays to ensure they are 1D
actual_prices = actual_prices.flatten()
lstm_predicted_prices = lstm_predicted_prices.flatten()
hybrid_predicted_prices = hybrid_predicted_prices.flatten()

# Ensure that all arrays have the same length
assert len(actual_prices) == len(lstm_predicted_prices) == len(hybrid_predicted_prices)

# Calculate accuracy using Mean Absolute Percentage Error (MAPE) with epsilon to avoid division by zero
epsilon = 1e-8  # small value to avoid division by zero
lstm_mape = np.mean(np.abs((actual_prices - lstm_predicted_prices) / (actual_prices + epsilon))) * 100
hybrid_mape = np.mean(np.abs((actual_prices - hybrid_predicted_prices) / (actual_prices + epsilon))) * 100

# Display accuracy for each model
print(f"LSTM Model Accuracy (MAPE): {100 - lstm_mape:.2f}%")
print(f"Hybrid CNN-LSTM Model Accuracy (MAPE): {100 - hybrid_mape:.2f}%")

# Visual Comparison: Plot Actual vs. Predicted Prices for Both Models
plt.figure(figsize=(14, 8))
plt.plot(actual_prices, label='Actual Price', color='blue', linestyle='-', linewidth=1.5)
plt.plot(lstm_predicted_prices, label='LSTM Predicted Price', color='red', linestyle='--', linewidth=1.5)
plt.plot(hybrid_predicted_prices, label='Hybrid CNN-LSTM Predicted Price', color='green', linestyle=':', linewidth=1.5)
plt.legend()
plt.title('Stock Price Prediction Comparison: LSTM vs. Hybrid CNN-LSTM')
plt.xlabel('Days')
plt.ylabel('Stock Price')
plt.show()

# Explanation of Difference in Accuracy: Highlight regions where each model performs better
plt.figure(figsize=(14, 6))
plt.plot(actual_prices, label='Actual Price', color='blue', linestyle='-', linewidth=1.5)
plt.plot(lstm_predicted_prices, label='LSTM Predicted Price', color='red', linestyle='--', linewidth=1.5)
plt.plot(hybrid_predicted_prices, label='Hybrid CNN-LSTM Predicted Price', color='green', linestyle=':', linewidth=1.5)

# Highlight regions where the LSTM model is closer to actual prices
plt.fill_between(range(len(actual_prices)), actual_prices, lstm_predicted_prices,
                 where=(np.abs(lstm_predicted_prices - actual_prices) < np.abs(hybrid_predicted_prices - actual_prices)),
                 color='lightcoral', alpha=0.3, label="LSTM Model Closer to Actual")

# Highlight regions where the Hybrid model is closer to actual prices
plt.fill_between(range(len(actual_prices)), actual_prices, hybrid_predicted_prices,
                 where=(np.abs(hybrid_predicted_prices - actual_prices) < np.abs(lstm_predicted_prices - actual_prices)),
                 color='lightgreen', alpha=0.3, label="Hybrid CNN-LSTM Model Closer to Actual")

plt.legend()
plt.title('Explainability: Regions of Accuracy for LSTM and Hybrid CNN-LSTM')
plt.xlabel('Days')
plt.ylabel('Stock Price')
plt.show()

from sklearn.metrics import mean_absolute_error, mean_squared_error

# Prediction on test data
predicted_prices_scaled = hybrid_model.predict([X_test_price, X_test_images])
predicted_prices = scaler_y.inverse_transform(predicted_prices_scaled.reshape(-1, 1)).flatten()
actual_prices = scaler_y.inverse_transform(y_test_images.reshape(-1, 1)).flatten()

# Calculate accuracy metrics
mae = mean_absolute_error(actual_prices, predicted_prices)
mse = mean_squared_error(actual_prices, predicted_prices)
rmse = np.sqrt(mse)
mape = np.mean(np.abs((actual_prices - predicted_prices) / actual_prices)) * 100  # Mean Absolute Percentage Error
accuracy = 100 - mape  # Accuracy as a percentage

print(f"Mean Absolute Error (MAE): {mae:.4f}")
print(f"Mean Squared Error (MSE): {mse:.4f}")
print(f"Root Mean Squared Error (RMSE): {rmse:.4f}")
print(f"Mean Absolute Percentage Error (MAPE): {mape:.2f}%")
print(f"Model Accuracy: {accuracy:.2f}%")

# Optional: Plot actual vs predicted prices for a visual assessment
plt.figure(figsize=(12, 6))
plt.plot(actual_prices, label="Actual Prices", color="blue")
plt.plot(predicted_prices, label="Predicted Prices", color="red")
plt.title("Actual vs Predicted Stock Prices")
plt.xlabel("Time Step")
plt.ylabel("Stock Price")
plt.legend()
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error
from tensorflow.keras.models import load_model

# Load the pre-trained models (adjust the paths as needed)
lstm_model = load_model('path_to_your_lstm_model.h5')  # Replace with your LSTM model path
hybrid_model = load_model('path_to_your_hybrid_model.h5')  # Replace with your Hybrid model path

# Predict stock prices using the trained LSTM model
lstm_predicted_prices = lstm_model.predict(X_test_price)
lstm_predicted_prices = scaler_y.inverse_transform(lstm_predicted_prices)  # Rescale to original price

# Predict stock prices using the trained Hybrid CNN-LSTM model
hybrid_predicted_prices = hybrid_model.predict([X_test_price, X_test_images])
hybrid_predicted_prices = scaler_y.inverse_transform(hybrid_predicted_prices)  # Rescale to original price

# Rescale actual prices back to original scale
actual_prices = scaler_y.inverse_transform(y_test_price.reshape(-1, 1))

# Flatten the arrays to ensure they are 1D
actual_prices = actual_prices.flatten()
lstm_predicted_prices = lstm_predicted_prices.flatten()
hybrid_predicted_prices = hybrid_predicted_prices.flatten()

# Ensure that all arrays have the same length
assert len(actual_prices) == len(lstm_predicted_prices) == len(hybrid_predicted_prices)

# Calculate RMSE (Root Mean Squared Error) for both models
lstm_rmse = np.sqrt(mean_squared_error(actual_prices, lstm_predicted_prices))
hybrid_rmse = np.sqrt(mean_squared_error(actual_prices, hybrid_predicted_prices))

# Display RMSE for each model
print(f"LSTM Model RMSE: {lstm_rmse:.4f}")
print(f"Hybrid CNN-LSTM Model RMSE: {hybrid_rmse:.4f}")

# Visual Comparison: Plot Actual vs. Predicted Prices for Both Models
plt.figure(figsize=(14, 8))
plt.plot(actual_prices, label='Actual Price', color='blue', linestyle='-', linewidth=1.5)
plt.plot(lstm_predicted_prices, label='LSTM Predicted Price', color='red', linestyle='--', linewidth=1.5)
plt.plot(hybrid_predicted_prices, label='Hybrid CNN-LSTM Predicted Price', color='green', linestyle=':', linewidth=1.5)
plt.legend()
plt.title('Stock Price Prediction Comparison: LSTM vs. Hybrid CNN-LSTM')
plt.xlabel('Days')
plt.ylabel('Stock Price')
plt.show()

# Explanation of Difference in Accuracy: Highlight regions where each model performs better
plt.figure(figsize=(14, 6))
plt.plot(actual_prices, label='Actual Price', color='blue', linestyle='-', linewidth=1.5)
plt.plot(lstm_predicted_prices, label='LSTM Predicted Price', color='red', linestyle='--', linewidth=1.5)
plt.plot(hybrid_predicted_prices, label='Hybrid CNN-LSTM Predicted Price', color='green', linestyle=':', linewidth=1.5)

# Highlight regions where the LSTM model is closer to actual prices
plt.fill_between(range(len(actual_prices)), actual_prices, lstm_predicted_prices,
                 where=(np.abs(lstm_predicted_prices - actual_prices) < np.abs(hybrid_predicted_prices - actual_prices)),
                 color='lightcoral', alpha=0.3, label="LSTM Model Closer to Actual")

# Highlight regions where the Hybrid model is closer to actual prices
plt.fill_between(range(len(actual_prices)), actual_prices, hybrid_predicted_prices,
                 where=(np.abs(hybrid_predicted_prices - actual_prices) < np.abs(lstm_predicted_prices - actual_prices)),
                 color='lightgreen', alpha=0.3, label="Hybrid CNN-LSTM Model Closer to Actual")

plt.legend()
plt.title('Explainability: Regions of Accuracy for LSTM and Hybrid CNN-LSTM')
plt.xlabel('Days')
plt.ylabel('Stock Price')
plt.show()